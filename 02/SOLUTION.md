# Day 2 Solution: Email Summarization Agent üß†

## üìù Reasoning & Logic
This agent is designed to "read" an unstructured text file (an email) and convert it into structured data (JSON). Unlike Rule-Based agents (Day 1) that rely on `if/else`, this agent relies on a **Large Language Model (LLM)** to understand context.

### Step-by-Step Flow
1.  **Ingestion**: The agent opens and reads `email.txt` as a raw string.
2.  **Prompting**: It packages the email content with a **System Prompt**. This is the "brain" of the operation. The prompt instructs the LLM not just to "summarize," but to "extract fields" into a specific JSON format.
3.  **Inference**: The request is sent to the LLM (Gemini via OpenAI compatibility layer). We set `temperature=0.2` to make the model factual and less creative.
4.  **Parsing**: The LLM returns a string resembling JSON. We parse this into a Python dictionary.
5.  **Output**: The agent saves the raw data to `summary.json` (for other programs to use) and a readable `summary.txt` (for humans).

---

## ü§ñ The System Prompt
The success of this agent depends entirely on this prompt. Notice how strict it is about the output format.

```python
SYSTEM_PROMPT = """
You are an Email Summarization Agent.

Your job:
1. Summarize the email in 2‚Äì3 sentences
2. Extract key points
3. Extract action items (who should do what)
4. Identify deadlines
5. Classify urgency: Low, Medium, or High

Return ONLY valid JSON with this schema:

{
  "summary": "",
  "key_points": [],
  "action_items": [],
  "deadlines": [],
  "urgency": ""
}
"""
```
**Why this works:**
*   **Role Definition**: "You are an Email Summarization Agent."
*   **Explicit Steps**: Numbered list of what to look for.
*   **Schema Enforcement**: Providing the exact JSON structure prevents the AI from inventing its own keys.

---

## üîç Code Breakdown

### 1. Sending the Request
We use the `client.chat.completions.create` method. Note the `response_format` isn't strictly used here because we are relying on prompt engineering, but newer models support structured outputs natively.

```python
def summarize_email(email_text):
    response = client.chat.completions.create(
        model="gemini-2.0-flash-exp", # Or gemini-1.5-flash
        messages=[
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": email_text}
        ],
        temperature=0.2 # Keep it deterministic
    )
    # The model returns a string, we simply parse it
    return json.loads(response.choices[0].message.content)
```

### 2. Saving the Output
We save two versions:
*   `summary.json`: The raw data object.
*   `summary.txt`: A formatted report generated by looping through the `action_items` and `key_points` lists.

---

## üõ°Ô∏è Edge Case Handling

1.  **Empty `email.txt`**:
    *   *Risk*: The API call might fail or return hallucinated content if the input is empty.
    *   *Fix*: Add a check `if not email_text: return` before calling the API.
2.  **Invalid JSON Response**:
    *   *Risk*: LLMs sometimes add markdown backticks (e.g., ` ```json { ... } ``` `) which causes `json.loads` to crash.
    *   *Fix*: Use a cleaning function to strip backticks or use a library like `pydantic` for strict validation.
    *   *Current Code*: Relies on the prompt "Return ONLY valid JSON" which is usually effective for strong models.
3.  **API Errors**:
    *   *Risk*: Network timeout or Quota exceeded.
    *   *Fix*: Wrap the API call in a `try/except` block to catch `openai.APIError`.

## üöÄ Further Improvements
*   **Batch Processing**: Modify `read_email` to loop through a folder of emails.
*   **Auto-Reply**: Use the `action_items` to draft a reply email automatically.
